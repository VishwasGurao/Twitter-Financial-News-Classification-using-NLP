{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d64c9994-e91c-4c54-97bc-d568192e0cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully loaded.\n",
      "Training data shape   : (16990, 2)\n",
      "Validation data shape : (4117, 2)\n",
      "\n",
      "Missing values in training dataset:\n",
      "text          0\n",
      "label         0\n",
      "clean_text    0\n",
      "dtype: int64\n",
      "\n",
      "Label distribution in training dataset:\n",
      "label\n",
      "0      255\n",
      "1      837\n",
      "2     3545\n",
      "3      321\n",
      "4      359\n",
      "5      987\n",
      "6      524\n",
      "7      624\n",
      "8      166\n",
      "9     1557\n",
      "10      69\n",
      "11      44\n",
      "12     487\n",
      "13     471\n",
      "14    1822\n",
      "15     501\n",
      "16     985\n",
      "17     495\n",
      "18    2118\n",
      "19     823\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Text length statistics (training data):\n",
      "count    16990.000000\n",
      "mean       100.452796\n",
      "std         49.726920\n",
      "min          0.000000\n",
      "25%         65.000000\n",
      "50%         88.000000\n",
      "75%        129.000000\n",
      "max        276.000000\n",
      "Name: text_length, dtype: float64\n",
      "\n",
      "Sample cleaned records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are Thursday's biggest analyst calls: Apple, Amazon, Tesla, Palantir, DocuSign, Exxon &amp;amp; more  https://t.co/QPN8Gwl7Uh</td>\n",
       "      <td>here are thursdays biggest analyst calls apple amazon tesla palantir docusign exxon amp more</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buy Las Vegas Sands as travel to Singapore builds, Wells Fargo says  https://t.co/fLS2w57iCz</td>\n",
       "      <td>buy las vegas sands as travel to singapore builds wells fargo says</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piper Sandler downgrades DocuSign to sell, citing elevated risks amid CEO transition  https://t.co/1EmtywmYpr</td>\n",
       "      <td>piper sandler downgrades docusign to sell citing elevated risks amid ceo transition</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analysts react to Tesla's latest earnings, break down what's next for electric car maker  https://t.co/kwhoE6W06u</td>\n",
       "      <td>analysts react to teslas latest earnings break down whats next for electric car maker</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netflix and its peers are set for a ‘return to growth,’ analysts say, giving one stock 120% upside  https://t.co/jPpdl0D9s4</td>\n",
       "      <td>netflix and its peers are set for a return to growth analysts say giving one stock upside</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             text  \\\n",
       "0  Here are Thursday's biggest analyst calls: Apple, Amazon, Tesla, Palantir, DocuSign, Exxon &amp; more  https://t.co/QPN8Gwl7Uh   \n",
       "1                                    Buy Las Vegas Sands as travel to Singapore builds, Wells Fargo says  https://t.co/fLS2w57iCz   \n",
       "2                   Piper Sandler downgrades DocuSign to sell, citing elevated risks amid CEO transition  https://t.co/1EmtywmYpr   \n",
       "3               Analysts react to Tesla's latest earnings, break down what's next for electric car maker  https://t.co/kwhoE6W06u   \n",
       "4     Netflix and its peers are set for a ‘return to growth,’ analysts say, giving one stock 120% upside  https://t.co/jPpdl0D9s4   \n",
       "\n",
       "                                                                                     clean_text  \\\n",
       "0  here are thursdays biggest analyst calls apple amazon tesla palantir docusign exxon amp more   \n",
       "1                            buy las vegas sands as travel to singapore builds wells fargo says   \n",
       "2           piper sandler downgrades docusign to sell citing elevated risks amid ceo transition   \n",
       "3         analysts react to teslas latest earnings break down whats next for electric car maker   \n",
       "4     netflix and its peers are set for a return to growth analysts say giving one stock upside   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned datasets saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Twitter Financial News Sentiment Analysis\n",
    "# Step 1: Data Loading and Text Cleaning\n",
    "# ============================================================\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Configure display settings for better readability\n",
    "pd.set_option(\"display.max_colwidth\", 150)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load training and validation datasets\n",
    "# ------------------------------------------------------------\n",
    "train_path = \"../data/train_data.csv\"\n",
    "valid_path = \"../data/valid_data.csv\"\n",
    "\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_valid = pd.read_csv(valid_path)\n",
    "\n",
    "print(\"Dataset successfully loaded.\")\n",
    "print(f\"Training data shape   : {df_train.shape}\")\n",
    "print(f\"Validation data shape : {df_valid.shape}\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Define text cleaning function\n",
    "# Purpose:\n",
    "# - Normalize text\n",
    "# - Remove noise such as URLs, punctuation, and numbers\n",
    "# - Prepare text for NLP modeling\n",
    "# ------------------------------------------------------------\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()                              # Convert to lowercase\n",
    "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)            # Remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)               # Remove punctuation and numbers\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()              # Remove extra whitespace\n",
    "    return text\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Apply text cleaning to both datasets\n",
    "# ------------------------------------------------------------\n",
    "df_train[\"clean_text\"] = df_train[\"text\"].apply(clean_text)\n",
    "df_valid[\"clean_text\"] = df_valid[\"text\"].apply(clean_text)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Basic data quality checks\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nMissing values in training dataset:\")\n",
    "print(df_train.isnull().sum())\n",
    "\n",
    "print(\"\\nLabel distribution in training dataset:\")\n",
    "print(df_train[\"label\"].value_counts().sort_index())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Feature engineering: text length\n",
    "# Useful for EDA and model diagnostics\n",
    "# ------------------------------------------------------------\n",
    "df_train[\"text_length\"] = df_train[\"clean_text\"].apply(len)\n",
    "\n",
    "print(\"\\nText length statistics (training data):\")\n",
    "print(df_train[\"text_length\"].describe())\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Display sample records to verify cleaning\n",
    "# ------------------------------------------------------------\n",
    "print(\"\\nSample cleaned records:\")\n",
    "display(df_train[[\"text\", \"clean_text\", \"label\"]].head(5))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Save cleaned datasets for downstream tasks\n",
    "# ------------------------------------------------------------\n",
    "df_train.to_csv(\"../data/train_clean.csv\", index=False)\n",
    "df_valid.to_csv(\"../data/valid_clean.csv\", index=False)\n",
    "\n",
    "print(\"\\nCleaned datasets saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aceb9d-08ed-4fc5-a5f5-76182969d6c3",
   "metadata": {},
   "source": [
    "\n",
    "# Twitter Financial News Sentiment Analysis\n",
    "\n",
    "## Project Overview\n",
    "This project focuses on analyzing and classifying finance-related Twitter news using Natural Language Processing (NLP) techniques. The primary objective is to transform unstructured financial tweets into clean, structured data and prepare it for machine learning–based sentiment and category classification.\n",
    "\n",
    "## Dataset Description\n",
    "The dataset consists of English-language tweets related to financial markets, companies, and economic events. Each tweet is annotated with one of multiple finance-related labels. The dataset exhibits a significant class imbalance, making it a realistic and challenging multi-class classification problem.\n",
    "\n",
    "## Data Preprocessing\n",
    "The initial phase of the project involved comprehensive data cleaning and preparation:\n",
    "- Loaded training and validation datasets from CSV files\n",
    "- Normalized text by converting it to lowercase\n",
    "- Removed noise such as URLs, punctuation, numbers, and extra whitespace\n",
    "- Generated a cleaned text column for downstream NLP tasks\n",
    "- Created an additional feature representing text length to support exploratory analysis\n",
    "\n",
    "## Data Quality Assessment\n",
    "Basic data validation checks were performed to ensure dataset reliability:\n",
    "- Verified the absence of critical missing values\n",
    "- Analyzed label distribution and identified class imbalance\n",
    "- Reviewed sample records to confirm the effectiveness of text cleaning\n",
    "\n",
    "## Output Artifacts\n",
    "Cleaned versions of the training and validation datasets were saved for reuse in subsequent stages, including exploratory data analysis, feature engineering, and model development.\n",
    "\n",
    "## Key Takeaways\n",
    "- Proper text preprocessing is essential for effective NLP modeling\n",
    "- Financial news data is inherently imbalanced and requires careful handling during model training\n",
    "- Establishing a clean and reproducible data pipeline improves model reliability and project scalability\n",
    "\n",
    "## Next Steps\n",
    "The next phase of the project will focus on exploratory data analysis (EDA) to uncover patterns in tweet content, label distribution, and text characteristics, followed by feature engineering and machine learning model development.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
