{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f70bd4be-76f7-4762-89d8-6151764c10ae",
   "metadata": {},
   "source": [
    "## Feature Engineering: Data Preparation\n",
    "\n",
    "This step loads the cleaned dataset and removes low-quality records\n",
    "such as missing or extremely short text entries to ensure reliable\n",
    "feature generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a63d56fc-f6fd-4002-abf5-879d2eeeebca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial dataset shape:\n",
      "(16990, 4)\n",
      "\n",
      "Dataset shape after cleaning edge cases:\n",
      "(16949, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load cleaned dataset\n",
    "data_path = \"../data/train_clean.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(\"Initial dataset shape:\")\n",
    "print(df.shape)\n",
    "\n",
    "# Remove rows with missing cleaned text\n",
    "df_fe = df.dropna(subset=[\"clean_text\"]).copy()\n",
    "\n",
    "# Remove very short texts (low information content)\n",
    "MIN_TEXT_LENGTH = 10\n",
    "df_fe = df_fe[df_fe[\"clean_text\"].str.len() > MIN_TEXT_LENGTH]\n",
    "\n",
    "print(\"\\nDataset shape after cleaning edge cases:\")\n",
    "print(df_fe.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580614a7-864a-4ab7-b5de-524d1ed3cc1f",
   "metadata": {},
   "source": [
    "## Feature and Target Definition\n",
    "\n",
    "This step separates the input text features and target labels\n",
    "required for supervised learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e9acb1-e05c-437b-b24e-8b01efa0daaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature sample:\n",
      "0    here are thursdays biggest analyst calls apple...\n",
      "1    buy las vegas sands as travel to singapore bui...\n",
      "2    piper sandler downgrades docusign to sell citi...\n",
      "Name: clean_text, dtype: object\n",
      "\n",
      "Target label sample:\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "5    0\n",
      "6    0\n",
      "7    0\n",
      "8    0\n",
      "9    0\n"
     ]
    }
   ],
   "source": [
    "# Define input features and target variable\n",
    "X = df_fe[\"clean_text\"]\n",
    "y = df_fe[\"label\"]\n",
    "\n",
    "print(\"Feature sample:\")\n",
    "print(X.head(3))\n",
    "\n",
    "print(\"\\nTarget label sample:\")\n",
    "print(y.head(10).to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7914d3f-6c5d-4116-8545-24b560ad592f",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "The dataset is split into training and testing sets while preserving\n",
    "class distribution to ensure fair model evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76fe4e41-c7c4-4a4e-9176-6c603f1e361e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Split Summary:\n",
      "Training samples : 13559\n",
      "Testing samples  : 3390\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train-Test Split Summary:\")\n",
    "print(f\"Training samples : {X_train.shape[0]}\")\n",
    "print(f\"Testing samples  : {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e730379-c5fc-4285-b0ef-7ad1c7df79d7",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization\n",
    "\n",
    "This step converts cleaned tweet text into numerical feature vectors\n",
    "using TF-IDF with unigrams and bigrams.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1215e96d-0e20-43eb-8938-32065732b231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Feature Matrix Shape:\n",
      "Training matrix : (13559, 5000)\n",
      "Testing matrix  : (3390, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=\"english\"\n",
    ")\n",
    "\n",
    "# Fit on training data and transform both sets\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "print(\"TF-IDF Feature Matrix Shape:\")\n",
    "print(f\"Training matrix : {X_train_tfidf.shape}\")\n",
    "print(f\"Testing matrix  : {X_test_tfidf.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c2d265-a591-4c32-8bea-63ca0f33e1f2",
   "metadata": {},
   "source": [
    "# Feature Engineering Summary\n",
    "\n",
    "This section outlines the steps performed to convert cleaned Twitter\n",
    "financial news text into structured numerical features suitable for\n",
    "machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Data Preparation\n",
    "The cleaned dataset was loaded and reviewed to ensure consistency and\n",
    "usability. Records with missing cleaned text were removed, as they do\n",
    "not provide meaningful information for text-based models.\n",
    "\n",
    "Additionally, tweets with extremely short text length were filtered\n",
    "out to reduce noise and improve the overall quality of the feature set.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Feature and Target Definition\n",
    "The cleaned tweet text was selected as the input feature, while the\n",
    "corresponding financial category label was used as the target variable.\n",
    "This clear separation ensures compatibility with supervised learning\n",
    "algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Train–Test Split\n",
    "The dataset was divided into training and testing sets using a\n",
    "stratified split. This approach preserves the original class\n",
    "distribution across both sets, which is essential given the imbalanced\n",
    "nature of the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Text Vectorization using TF-IDF\n",
    "Text data was transformed into numerical representations using\n",
    "Term Frequency–Inverse Document Frequency (TF-IDF) vectorization.\n",
    "\n",
    "Both unigrams and bigrams were included to capture individual financial\n",
    "terms as well as commonly occurring short phrases. The feature space\n",
    "was limited to the most informative terms to maintain computational\n",
    "efficiency and model stability.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Outcome of Feature Engineering\n",
    "The feature engineering process resulted in well-structured numerical\n",
    "feature matrices for both training and testing data. These features are\n",
    "fully compatible with baseline and advanced machine learning models and\n",
    "provide a strong foundation for accurate financial news classification.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Conclusion\n",
    "The feature engineering phase successfully converted unstructured text\n",
    "data into high-quality numerical features. The resulting dataset is\n",
    "clean, balanced at the split level, and ready for model training and\n",
    "evaluation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
